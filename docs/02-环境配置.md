# 02. 环境配置

本指南将帮助你配置 DiT 文生图项目的开发环境。

## 系统要求

### 硬件要求

- **GPU**：NVIDIA GPU（推荐 RTX 4090 或更高）
  - 显存：至少 24GB（RTX 4090）
  - CUDA 计算能力：7.5 或更高
- **内存**：至少 16GB RAM
- **存储**：至少 50GB 可用空间（用于模型和数据）

### 软件要求

- **操作系统**：Linux（推荐 Ubuntu 20.04+）或 Windows
- **Python**：3.8 或更高版本（推荐 3.9 或 3.10）
- **CUDA**：11.8 或更高版本
- **cuDNN**：与 CUDA 版本匹配

## 安装步骤

### 1. 安装 Python

#### Linux

```bash
# 使用 conda（推荐）
conda create -n dit python=3.10
conda activate dit

# 或使用系统 Python
python3 --version  # 检查版本
```

#### Windows

下载并安装 Python 3.10：
- 访问 [Python 官网](https://www.python.org/downloads/)
- 下载 Python 3.10
- 安装时勾选 "Add Python to PATH"

### 2. 安装 CUDA 和 PyTorch

#### 检查 CUDA 版本

```bash
nvidia-smi  # 查看 CUDA 版本
```

#### 安装 PyTorch

访问 [PyTorch 官网](https://pytorch.org/) 获取安装命令，或使用以下命令：

```bash
# CUDA 11.8
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# CUDA 12.1
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

#### 验证安装

```python
import torch
print(torch.__version__)
print(torch.cuda.is_available())
print(torch.cuda.get_device_name(0))
```

### 3. 安装项目依赖

#### 克隆或下载项目

```bash
cd /path/to/your/workspace
# 如果使用 git
# git clone <repository-url>
```

#### 安装依赖

```bash
# 进入项目目录
cd t2i2

# 安装依赖
pip install -r requirements.txt
```

#### 主要依赖说明

- **torch**：PyTorch 深度学习框架
- **diffusers**：Hugging Face 扩散模型库
- **transformers**：Hugging Face Transformer 模型库
- **accelerate**：训练加速库
- **datasets**：数据集管理库

### 4. 安装项目（可选）

```bash
# 以开发模式安装
pip install -e .
```

## 验证安装

### 创建测试脚本

创建 `test_installation.py`：

```python
import torch
from diffusers import DDPMScheduler
from transformers import CLIPTextModel, CLIPTokenizer

print("PyTorch 版本:", torch.__version__)
print("CUDA 可用:", torch.cuda.is_available())
if torch.cuda.is_available():
    print("GPU 名称:", torch.cuda.get_device_name(0))
    print("GPU 显存:", torch.cuda.get_device_properties(0).total_memory / 1e9, "GB")

print("\n测试 Diffusers...")
scheduler = DDPMScheduler()
print("✓ Diffusers 正常")

print("\n测试 Transformers...")
tokenizer = CLIPTokenizer.from_pretrained("openai/clip-vit-base-patch32")
print("✓ Transformers 正常")

print("\n✓ 所有依赖安装成功！")
```

### 运行测试

```bash
python test_installation.py
```

## 常见问题

### 1. CUDA 不可用

**问题**：`torch.cuda.is_available()` 返回 `False`

**解决方案**：
- 检查 NVIDIA 驱动是否正确安装
- 确认 CUDA 版本与 PyTorch 版本匹配
- 重新安装匹配的 PyTorch 版本

### 2. 内存不足

**问题**：训练时出现 OOM（Out of Memory）错误

**解决方案**：
- 减小批次大小（batch_size）
- 使用梯度累积（gradient_accumulation_steps）
- 启用混合精度训练（mixed_precision="fp16"）
- 使用 VAE 切片（enable_slicing）

### 3. 下载模型失败

**问题**：无法从 Hugging Face 下载预训练模型

**解决方案**：
- 检查网络连接
- 使用镜像站点（如果在中国）
- 手动下载模型到本地

### 4. 依赖冲突

**问题**：不同库的版本冲突

**解决方案**：
- 使用虚拟环境（conda 或 venv）
- 按照 requirements.txt 安装指定版本
- 如果仍有问题，尝试更新到最新版本

## 环境变量配置（可选）

### 设置 Hugging Face 缓存目录

```bash
export HF_HOME=/path/to/huggingface/cache
```

### 设置 CUDA 设备

```bash
export CUDA_VISIBLE_DEVICES=0  # 使用第一块 GPU
```

## 下一步

环境配置完成后，可以：

1. 阅读 [数据准备](./03-数据准备.md) 准备训练数据
2. 阅读 [训练流程](./05-训练流程.md) 开始训练
3. 查看 [常见问题](./07-常见问题.md) 了解更多

---

**环境配置完成！让我们准备数据吧！** 📦



