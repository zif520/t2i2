# 04. 模型架构

本章将深入讲解 DiT (Diffusion Transformer) 模型的架构设计。

## 整体架构

DiT 模型由以下几个核心组件组成：

```
文本输入 → CLIP文本编码器 → 文本嵌入
图像输入 → VAE编码器 → 潜在表示
时间步 → 时间步嵌入
                    ↓
            DiT Transformer
                    ↓
            预测噪声
                    ↓
            VAE解码器 → 生成图像
```

## 核心组件

### 1. VAE (变分自编码器)

VAE 用于在图像空间和潜在空间之间转换。

#### VAE 编码器

- **输入**：RGB 图像 (B, 3, H, W)，值范围 [-1, 1]
- **输出**：潜在表示 (B, 4, H/8, W/8)
- **作用**：将图像压缩到潜在空间，降低计算量

#### VAE 解码器

- **输入**：潜在表示 (B, 4, H, W)
- **输出**：RGB 图像 (B, 3, H*8, W*8)，值范围 [-1, 1]
- **作用**：将潜在表示解码回图像空间

**为什么使用 VAE？**
- 降低计算量：在潜在空间（更小）进行扩散，而不是在像素空间
- 提高效率：8倍下采样，大大减少计算

### 2. 文本编码器 (CLIP)

使用 CLIP 的文本编码器将文本转换为向量。

- **输入**：文本字符串
- **输出**：文本嵌入 (B, 77, 768)
- **作用**：将文本描述编码为模型可理解的向量

### 3. DiT Transformer

这是模型的核心部分。

#### 输入处理

1. **Patch 嵌入**
   - 将潜在表示分割成 patches
   - 使用卷积层将每个 patch 转换为嵌入向量
   - 输入：(B, 4, H, W) → 输出：(B, N, hidden_size)

2. **位置嵌入**
   - 为每个 patch 添加位置信息
   - 使用可学习的位置嵌入

3. **时间步嵌入**
   - 将时间步编码为向量
   - 使用正弦位置编码 + MLP

4. **文本条件嵌入**
   - 将文本嵌入投影到模型维度
   - 与时间步嵌入相加

#### Transformer 块

每个 Transformer 块包含：

1. **自注意力层**
   - 多头自注意力机制
   - 允许模型关注不同的 patches

2. **前馈网络 (MLP)**
   - 两层全连接网络
   - 使用 SiLU 激活函数

3. **条件注入**
   - 在每个块中注入时间步和文本条件
   - 使用 AdaLN (Adaptive Layer Normalization)

#### 输出层

- **AdaLN**：自适应层归一化
- **线性层**：输出预测的噪声
- **重塑**：将输出重塑为图像格式

## 模型参数配置

### 小模型配置（适配 RTX 4090）

```yaml
model:
  hidden_size: 384        # 隐藏层维度
  num_layers: 8           # Transformer 层数
  num_heads: 6            # 注意力头数
  patch_size: 2           # Patch 大小
  in_channels: 4          # 输入通道（VAE 潜在空间）
  out_channels: 4         # 输出通道
  attention_head_dim: 64  # 注意力头维度
  mlp_ratio: 4.0          # MLP 扩展比例
  dropout: 0.1           # Dropout 率
```

### 参数说明

- **hidden_size**：模型的主要维度，影响模型容量
- **num_layers**：Transformer 层数，影响模型深度
- **num_heads**：注意力头数，影响模型的表达能力
- **patch_size**：将图像分割成多大的 patches

### 计算量估算

对于 256x256 图像：
- 潜在空间尺寸：32x32
- Patch 数量：16x16 = 256
- 每步计算量：约 1-2 GB 显存（小模型）

## 扩散过程

### 前向过程（训练）

1. 图像编码到潜在空间
2. 随机采样时间步 t
3. 根据时间步添加噪声
4. 模型预测噪声
5. 计算损失

### 反向过程（推理）

1. 从随机噪声开始
2. 逐步去噪（T 步）
3. 每步使用模型预测噪声
4. 使用调度器更新潜在表示
5. 解码为图像

## 条件注入机制

DiT 使用条件注入来融合文本和时间步信息：

### 方式 1：相加注入

```python
# 时间步嵌入 + 文本嵌入
condition = timestep_embedding + text_embedding
```

### 方式 2：AdaLN（自适应层归一化）

```python
# 在每个 Transformer 块中
shift, scale = ada_ln_modulation(condition)
x = layer_norm(x) * (1 + scale) + shift
```

## 代码结构

### 模型定义

```python
class DiTModel(nn.Module):
    def __init__(self, ...):
        # Patch 嵌入
        self.x_embedder = ...
        # 位置嵌入
        self.pos_embed = ...
        # 时间步嵌入
        self.t_embedder = ...
        # 文本条件嵌入
        self.y_embedder = ...
        # Transformer 块
        self.blocks = ...
        # 最终层
        self.final_layer = ...
    
    def forward(self, x, t, y):
        # Patch 嵌入
        x = self.x_embedder(x)
        # 添加位置嵌入
        x = x + self.pos_embed
        # 时间步和文本嵌入
        t_emb = self.t_embedder(t)
        y_emb = self.y_embedder(y)
        c = t_emb + y_emb
        # Transformer 块
        for block in self.blocks:
            x = block(x, c)
        # 输出
        x = self.final_layer(x, c)
        return x
```

## 模型扩展

### 增大模型

可以通过以下方式增大模型：

1. **增加 hidden_size**：384 → 768 → 1024
2. **增加 num_layers**：8 → 12 → 24
3. **增加 num_heads**：6 → 12 → 16

**注意**：增大模型会显著增加显存需求。

### 优化技巧

1. **混合精度训练**：使用 FP16 减少显存
2. **梯度检查点**：以时间换显存
3. **模型并行**：多 GPU 训练

## 与其他架构的对比

### DiT vs Stable Diffusion

- **DiT**：使用 Transformer 作为主干
- **Stable Diffusion**：使用 U-Net 作为主干

### DiT vs DALL-E 2

- **DiT**：端到端训练
- **DALL-E 2**：两阶段训练（先 VAE，再扩散）

## 下一步

理解模型架构后，可以：

1. 阅读 [训练流程](./05-训练流程.md) 了解如何训练
2. 调整模型参数进行实验
3. 查看代码实现细节

---

**模型架构理解完成！让我们开始训练吧！** 🎯



