# 05. è®­ç»ƒæµç¨‹

æœ¬æŒ‡å—å°†è¯¦ç»†ä»‹ç»å¦‚ä½•è®­ç»ƒ DiT æ¨¡å‹ã€‚

## è®­ç»ƒå‰å‡†å¤‡

### 1. æ£€æŸ¥ç¯å¢ƒ

```bash
# æ£€æŸ¥ GPU
nvidia-smi

# æ£€æŸ¥ PyTorch
python -c "import torch; print(torch.cuda.is_available())"
```

### 2. å‡†å¤‡æ•°æ®

å‚è€ƒ [æ•°æ®å‡†å¤‡](./03-æ•°æ®å‡†å¤‡.md) å‡†å¤‡è®­ç»ƒæ•°æ®ã€‚

### 3. æ£€æŸ¥é…ç½®æ–‡ä»¶

ç¡®è®¤ `configs/train_config.yaml` ä¸­çš„é…ç½®æ­£ç¡®ï¼š

```yaml
data:
  dataset_name: "coco"  # æˆ– "custom"
  dataset_path: "./data"
  image_size: 256
  num_samples: 5000

training:
  batch_size: 4
  num_epochs: 50
  learning_rate: 1e-4
```

## å¼€å§‹è®­ç»ƒ

### åŸºæœ¬è®­ç»ƒå‘½ä»¤

```bash
python src/scripts/train.py --config configs/train_config.yaml
```

### ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®

```bash
python src/scripts/train.py \
    --config configs/train_config.yaml \
    --data.dataset_name custom \
    --data.dataset_path ./data/custom
```

### æ¢å¤è®­ç»ƒ

```bash
python src/scripts/train.py \
    --config configs/train_config.yaml \
    --resume ./outputs/checkpoint-1000
```

## è®­ç»ƒå‚æ•°è¯¦è§£

### æ‰¹æ¬¡å¤§å° (batch_size)

- **é»˜è®¤å€¼**ï¼š4
- **è¯´æ˜**ï¼šæ¯æ¬¡è®­ç»ƒçš„æ ·æœ¬æ•°
- **è°ƒæ•´å»ºè®®**ï¼š
  - æ˜¾å­˜å……è¶³ï¼šå¯ä»¥å¢åŠ åˆ° 8 æˆ– 16
  - æ˜¾å­˜ä¸è¶³ï¼šå‡å°‘åˆ° 2ï¼Œå¢åŠ æ¢¯åº¦ç´¯ç§¯æ­¥æ•°

### æ¢¯åº¦ç´¯ç§¯ (gradient_accumulation_steps)

- **é»˜è®¤å€¼**ï¼š4
- **è¯´æ˜**ï¼šç´¯ç§¯å¤šä¸ªæ‰¹æ¬¡çš„æ¢¯åº¦å†æ›´æ–°
- **æ•ˆæœ**ï¼šç›¸å½“äº batch_size = 4 * 4 = 16

### å­¦ä¹ ç‡ (learning_rate)

- **é»˜è®¤å€¼**ï¼š1e-4
- **è¯´æ˜**ï¼šæ¨¡å‹å‚æ•°æ›´æ–°çš„æ­¥é•¿
- **è°ƒæ•´å»ºè®®**ï¼š
  - å¦‚æœæŸå¤±ä¸ä¸‹é™ï¼šå°è¯•å‡å°ï¼ˆå¦‚ 5e-5ï¼‰
  - å¦‚æœè®­ç»ƒä¸ç¨³å®šï¼šå°è¯•å‡å°

### è®­ç»ƒè½®æ•° (num_epochs)

- **é»˜è®¤å€¼**ï¼š50
- **è¯´æ˜**ï¼šå®Œæ•´éå†æ•°æ®é›†çš„æ¬¡æ•°
- **è°ƒæ•´å»ºè®®**ï¼š
  - å°æ•°æ®é›†ï¼šå¯èƒ½éœ€è¦æ›´å¤šè½®æ•°
  - å¤§æ•°æ®é›†ï¼šå¯èƒ½æ›´å°‘è½®æ•°å°±è¶³å¤Ÿ

### æ··åˆç²¾åº¦ (mixed_precision)

- **é»˜è®¤å€¼**ï¼šfp16
- **è¯´æ˜**ï¼šä½¿ç”¨åŠç²¾åº¦æµ®ç‚¹æ•°è®­ç»ƒ
- **ä¼˜åŠ¿**ï¼šå‡å°‘æ˜¾å­˜ä½¿ç”¨ï¼ŒåŠ å¿«è®­ç»ƒé€Ÿåº¦
- **æ³¨æ„**ï¼šå¯èƒ½å¯¼è‡´æ•°å€¼ä¸ç¨³å®š

## è®­ç»ƒè¿‡ç¨‹ç›‘æ§

### æ—¥å¿—è¾“å‡º

è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šè¾“å‡ºï¼š

```
Epoch 1/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1250/1250 [10:30<00:00, loss=0.1234]
Step 50, Loss: 0.1234, LR: 1.00e-04
Step 100, Loss: 0.0987, LR: 1.00e-04
...
```

### æ£€æŸ¥ç‚¹ä¿å­˜

è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šå®šæœŸä¿å­˜æ£€æŸ¥ç‚¹ï¼š

```
outputs/
â”œâ”€â”€ checkpoint-500/
â”‚   â”œâ”€â”€ model.pt
â”‚   â”œâ”€â”€ optimizer.pt
â”‚   â””â”€â”€ training_state.json
â”œâ”€â”€ checkpoint-1000/
â”‚   â””â”€â”€ ...
â””â”€â”€ checkpoint-epoch-1/
    â””â”€â”€ ...
```

### ä½¿ç”¨ TensorBoardï¼ˆå¯é€‰ï¼‰

```bash
# å¯åŠ¨ TensorBoard
tensorboard --logdir ./outputs

# åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€
# http://localhost:6006
```

## è®­ç»ƒæŠ€å·§

### 1. å­¦ä¹ ç‡è°ƒåº¦

ä½¿ç”¨ä½™å¼¦é€€ç«è°ƒåº¦å™¨ï¼š

```yaml
lr_scheduler:
  type: "cosine"
  warmup_steps: 500
```

### 2. æ¢¯åº¦è£å‰ª

é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼š

```yaml
training:
  max_grad_norm: 1.0
```

### 3. EMAï¼ˆæŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼‰

ç¨³å®šè®­ç»ƒè¿‡ç¨‹ï¼š

```yaml
training:
  use_ema: true
  ema_decay: 0.9999
```

### 4. æ•°æ®å¢å¼º

åœ¨æ•°æ®åŠ è½½æ—¶è‡ªåŠ¨è¿›è¡Œï¼š

- éšæœºæ°´å¹³ç¿»è½¬
- éšæœºè£å‰ªï¼ˆå¯é€‰ï¼‰

## è®­ç»ƒä¼˜åŒ–

### æ˜¾å­˜ä¼˜åŒ–

å¦‚æœé‡åˆ° OOMï¼ˆå†…å­˜ä¸è¶³ï¼‰é”™è¯¯ï¼š

1. **å‡å°æ‰¹æ¬¡å¤§å°**
   ```yaml
   training:
     batch_size: 2  # ä» 4 å‡å°åˆ° 2
   ```

2. **å¯ç”¨ VAE åˆ‡ç‰‡**
   ```yaml
   vae:
     use_slicing: true
   ```

3. **ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹**ï¼ˆå¦‚æœæ”¯æŒï¼‰

### é€Ÿåº¦ä¼˜åŒ–

1. **ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ**
   ```yaml
   training:
     mixed_precision: "fp16"
   ```

2. **å¢åŠ æ•°æ®åŠ è½½çº¿ç¨‹**
   ```python
   DataLoader(..., num_workers=4)
   ```

3. **ä½¿ç”¨ç¼–è¯‘ä¼˜åŒ–**ï¼ˆPyTorch 2.0+ï¼‰
   ```python
   model = torch.compile(model)
   ```

## è®­ç»ƒæ£€æŸ¥æ¸…å•

### è®­ç»ƒå‰

- [ ] æ•°æ®å·²å‡†å¤‡å¹¶éªŒè¯
- [ ] é…ç½®æ–‡ä»¶å·²æ£€æŸ¥
- [ ] GPU å¯ç”¨ä¸”æ˜¾å­˜å……è¶³
- [ ] ä¾èµ–å·²å®‰è£…

### è®­ç»ƒä¸­

- [ ] æŸå¤±å€¼åœ¨ä¸‹é™
- [ ] æ²¡æœ‰ NaN æˆ– Inf
- [ ] æ£€æŸ¥ç‚¹æ­£å¸¸ä¿å­˜
- [ ] è®­ç»ƒé€Ÿåº¦åˆç†

### è®­ç»ƒå

- [ ] æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜
- [ ] è®­ç»ƒæ—¥å¿—å®Œæ•´
- [ ] å¯ä»¥åŠ è½½æ£€æŸ¥ç‚¹
- [ ] å¯ä»¥è¿›è¡Œæ¨ç†

## å¸¸è§é—®é¢˜

### 1. æŸå¤±ä¸ä¸‹é™

**å¯èƒ½åŸå› ï¼š**
- å­¦ä¹ ç‡å¤ªå¤§æˆ–å¤ªå°
- æ•°æ®æœ‰é—®é¢˜
- æ¨¡å‹åˆå§‹åŒ–ä¸å½“

**è§£å†³æ–¹æ¡ˆï¼š**
- è°ƒæ•´å­¦ä¹ ç‡
- æ£€æŸ¥æ•°æ®è´¨é‡
- æ£€æŸ¥æ¨¡å‹è¾“å‡º

### 2. è®­ç»ƒé€Ÿåº¦æ…¢

**å¯èƒ½åŸå› ï¼š**
- æ•°æ®åŠ è½½æ…¢
- æ¨¡å‹å¤ªå¤§
- æ²¡æœ‰ä½¿ç”¨æ··åˆç²¾åº¦

**è§£å†³æ–¹æ¡ˆï¼š**
- å¢åŠ  num_workers
- å‡å°æ¨¡å‹å¤§å°
- å¯ç”¨æ··åˆç²¾åº¦

### 3. æ˜¾å­˜ä¸è¶³

**å¯èƒ½åŸå› ï¼š**
- æ‰¹æ¬¡å¤ªå¤§
- æ¨¡å‹å¤ªå¤§
- å›¾åƒå°ºå¯¸å¤ªå¤§

**è§£å†³æ–¹æ¡ˆï¼š**
- å‡å° batch_size
- å‡å°æ¨¡å‹å‚æ•°
- å‡å° image_size

## è®­ç»ƒæ—¶é—´ä¼°ç®—

å¯¹äºå°æ¨¡å‹å’Œå°æ•°æ®é›†ï¼ˆRTX 4090ï¼‰ï¼š

- **5000 æ ·æœ¬ï¼Œbatch_size=4**ï¼šçº¦ 2-4 å°æ—¶/epoch
- **50 epochs**ï¼šçº¦ 100-200 å°æ—¶

**æ³¨æ„**ï¼šå®é™…æ—¶é—´å–å†³äºç¡¬ä»¶å’Œæ•°æ®ã€‚

## ä¸‹ä¸€æ­¥

è®­ç»ƒå®Œæˆåï¼Œå¯ä»¥ï¼š

1. é˜…è¯» [æ¨ç†ä½¿ç”¨](./06-æ¨ç†ä½¿ç”¨.md) ä½¿ç”¨æ¨¡å‹ç”Ÿæˆå›¾åƒ
2. è¯„ä¼°æ¨¡å‹æ€§èƒ½
3. è°ƒæ•´è¶…å‚æ•°ç»§ç»­è®­ç»ƒ

---

**è®­ç»ƒå®Œæˆï¼è®©æˆ‘ä»¬ç”Ÿæˆä¸€äº›å›¾åƒå§ï¼** ğŸ¨



