# 07. é…ç½®å‚è€ƒ

æœ¬æŒ‡å—è¯¦ç»†è¯´æ˜ `configs/train_config.yaml` é…ç½®æ–‡ä»¶çš„æ‰€æœ‰å‚æ•°ã€‚

## ğŸ“‹ é…ç½®æ–‡ä»¶ç»“æ„

é…ç½®æ–‡ä»¶é‡‡ç”¨ YAML æ ¼å¼ï¼ŒåŒ…å«ä»¥ä¸‹ä¸»è¦éƒ¨åˆ†ï¼š

```yaml
data:          # æ•°æ®é…ç½®
model:         # æ¨¡å‹é…ç½®
vae:           # VAE é…ç½®
training:      # è®­ç»ƒé…ç½®
scheduler:     # æ‰©æ•£è°ƒåº¦å™¨é…ç½®
text_encoder:  # æ–‡æœ¬ç¼–ç å™¨é…ç½®
optimizer:     # ä¼˜åŒ–å™¨é…ç½®
lr_scheduler:  # å­¦ä¹ ç‡è°ƒåº¦å™¨é…ç½®
```

## ğŸ“Š æ•°æ®é…ç½® (`data`)

### å‚æ•°è¯´æ˜

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `dataset_name` | str | `"coco"` | æ•°æ®é›†åç§°: `"coco"`, `"cub"`, `"custom"` |
| `dataset_path` | str | `"./data"` | æ•°æ®é›†è·¯å¾„ï¼ˆè‡ªå®šä¹‰æ•°æ®é›†å¿…éœ€ï¼‰ |
| `image_size` | int | `256` | å›¾åƒå°ºå¯¸ï¼ˆæ¨è 256ï¼Œå¿…é¡»æ˜¯ 8 çš„å€æ•°ï¼‰ |
| `num_samples` | int | `5000` | ä½¿ç”¨çš„æ ·æœ¬æ•°é‡ï¼ˆNone è¡¨ç¤ºä½¿ç”¨å…¨éƒ¨ï¼‰ |
| `train_split` | float | `0.9` | è®­ç»ƒé›†æ¯”ä¾‹ï¼ˆå½“å‰æœªä½¿ç”¨ï¼Œæ‰€æœ‰æ•°æ®ç”¨äºè®­ç»ƒï¼‰ |

### ç¤ºä¾‹é…ç½®

```yaml
data:
  dataset_name: "cub"                    # ä½¿ç”¨ CUB æ•°æ®é›†
  dataset_path: "./data/cub_subset"      # CUB æ•°æ®é›†è·¯å¾„
  image_size: 256                        # 256x256 å›¾åƒ
  num_samples: 5000                      # ä½¿ç”¨ 5000 ä¸ªæ ·æœ¬
```

## ğŸ§  æ¨¡å‹é…ç½® (`model`)

### å‚æ•°è¯´æ˜

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `hidden_size` | int | `768` | éšè—å±‚ç»´åº¦ï¼ˆå½±å“æ¨¡å‹å®¹é‡ï¼‰ |
| `num_layers` | int | `16` | Transformer å±‚æ•°ï¼ˆå½±å“æ¨¡å‹æ·±åº¦ï¼‰ |
| `num_heads` | int | `12` | æ³¨æ„åŠ›å¤´æ•°ï¼ˆå¿…é¡»æ˜¯ hidden_size çš„çº¦æ•°ï¼‰ |
| `patch_size` | int | `2` | Patch å¤§å°ï¼ˆæ¨è 2ï¼‰ |
| `in_channels` | int | `4` | è¾“å…¥é€šé“æ•°ï¼ˆVAE æ½œåœ¨ç©ºé—´ï¼‰ |
| `out_channels` | int | `4` | è¾“å‡ºé€šé“æ•° |
| `attention_head_dim` | int | `64` | æ¯ä¸ªæ³¨æ„åŠ›å¤´çš„ç»´åº¦ |
| `mlp_ratio` | float | `4.0` | MLP æ‰©å±•æ¯”ä¾‹ |
| `dropout` | float | `0.1` | Dropout ç‡ |

### æ¨¡å‹è§„æ¨¡é…ç½®

#### å°æ¨¡å‹ï¼ˆå­¦ä¹ ç”¨ï¼‰

```yaml
model:
  hidden_size: 384
  num_layers: 8
  num_heads: 6
```

#### ä¸­ç­‰æ¨¡å‹ï¼ˆå½“å‰ï¼ŒRTX 4090 ä¼˜åŒ–ï¼‰

```yaml
model:
  hidden_size: 768
  num_layers: 16
  num_heads: 12
```

#### å¤§æ¨¡å‹ï¼ˆç ”ç©¶ç”¨ï¼‰

```yaml
model:
  hidden_size: 1024
  num_layers: 24
  num_heads: 16
```

### å‚æ•°è®¡ç®—

- **æ€»å‚æ•°é‡**: çº¦ `hidden_sizeÂ² * num_layers * 12`ï¼ˆç²—ç•¥ä¼°è®¡ï¼‰
- **å½“å‰é…ç½®**: çº¦ 150M å‚æ•°

## ğŸ¨ VAE é…ç½® (`vae`)

### å‚æ•°è¯´æ˜

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `pretrained_model_name` | str | `"runwayml/stable-diffusion-v1-5"` | é¢„è®­ç»ƒ VAE æ¨¡å‹åç§° |
| `use_slicing` | bool | `false` | æ˜¯å¦ä½¿ç”¨åˆ‡ç‰‡ï¼ˆèŠ‚çœæ˜¾å­˜ï¼Œä½†é™ä½é€Ÿåº¦ï¼‰ |

### å¯ç”¨æ¨¡å‹

- `"runwayml/stable-diffusion-v1-5"` (æ¨è) - Stable Diffusion 1.5 VAE
- `"stabilityai/sd-vae-ft-mse-original"` - MSE å¾®è°ƒç‰ˆæœ¬

### é…ç½®å»ºè®®

- **RTX 4090 (24GB)**: `use_slicing: false`ï¼ˆæ˜¾å­˜å……è¶³ï¼‰
- **è¾ƒå°æ˜¾å­˜**: `use_slicing: true`ï¼ˆèŠ‚çœæ˜¾å­˜ï¼‰

## ğŸ‹ï¸ è®­ç»ƒé…ç½® (`training`)

### æ ¸å¿ƒå‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `output_dir` | str | `"./outputs"` | è¾“å‡ºç›®å½• |
| `seed` | int | `42` | éšæœºç§å­ |
| `batch_size` | int | `96` | æ‰¹æ¬¡å¤§å°ï¼ˆRTX 4090 ä¼˜åŒ–ï¼‰ |
| `gradient_accumulation_steps` | int | `1` | æ¢¯åº¦ç´¯ç§¯æ­¥æ•° |
| `learning_rate` | float | `0.0001` | å­¦ä¹ ç‡ |
| `num_epochs` | int | `1000` | è®­ç»ƒè½®æ•° |
| `save_every_n_epochs` | int | `10` | æ¯ N ä¸ª epoch ä¿å­˜ä¸€æ¬¡ |
| `save_steps` | int | `500` | æ¯ N æ­¥ä¿å­˜ä¸€æ¬¡ï¼ˆå¯é€‰ï¼‰ |
| `logging_steps` | int | `50` | æ¯ N æ­¥è®°å½•æ—¥å¿— |
| `mixed_precision` | str | `"bf16"` | æ··åˆç²¾åº¦: `"fp16"`, `"bf16"`, `"no"` |
| `max_grad_norm` | float | `1.0` | æ¢¯åº¦è£å‰ªé˜ˆå€¼ |
| `use_ema` | bool | `false` | æ˜¯å¦ä½¿ç”¨ EMA |
| `ema_decay` | float | `0.9999` | EMA è¡°å‡ç‡ |
| `num_workers` | int | `8` | æ•°æ®åŠ è½½çº¿ç¨‹æ•° |
| `prefetch_factor` | int | `4` | é¢„å–å› å­ |
| `compile_model` | bool | `false` | æ˜¯å¦ç¼–è¯‘æ¨¡å‹ï¼ˆPyTorch 2.0+ï¼‰ |

### æ‰¹æ¬¡å¤§å°é…ç½®

æ ¹æ® GPU æ˜¾å­˜è°ƒæ•´ï¼š

```yaml
# RTX 4090 (24GB) - æœ€ä¼˜
training:
  batch_size: 96

# RTX 3090 (24GB)
training:
  batch_size: 64

# RTX 3080 (10GB)
training:
  batch_size: 16
  gradient_accumulation_steps: 4
```

### æ··åˆç²¾åº¦é€‰æ‹©

```yaml
# BF16 (æ¨èï¼ŒRTX 4090 åŸç”Ÿæ”¯æŒ)
training:
  mixed_precision: "bf16"

# FP16 (å…¼å®¹æ€§æ›´å¥½)
training:
  mixed_precision: "fp16"

# ä¸ä½¿ç”¨æ··åˆç²¾åº¦
training:
  mixed_precision: "no"
```

## â±ï¸ æ‰©æ•£è°ƒåº¦å™¨é…ç½® (`scheduler`)

### å‚æ•°è¯´æ˜

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `num_train_timesteps` | int | `1000` | è®­ç»ƒæ—¶é—´æ­¥æ•° |
| `beta_start` | float | `0.00085` | beta èµ·å§‹å€¼ |
| `beta_end` | float | `0.012` | beta ç»“æŸå€¼ |
| `beta_schedule` | str | `"scaled_linear"` | beta è°ƒåº¦æ–¹å¼ |
| `prediction_type` | str | `"epsilon"` | é¢„æµ‹ç±»å‹: `"epsilon"` æˆ– `"v_prediction"` |

### è°ƒåº¦å™¨ç±»å‹

- **DDPM**: é»˜è®¤ï¼Œæ ‡å‡†æ‰©æ•£è¿‡ç¨‹
- **DDIM**: æ›´å¿«ä½†å¯èƒ½è´¨é‡ç•¥ä½ï¼ˆæ¨ç†æ—¶å¯é€‰ï¼‰

## ğŸ“ æ–‡æœ¬ç¼–ç å™¨é…ç½® (`text_encoder`)

### å‚æ•°è¯´æ˜

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `pretrained_model_name` | str | `"openai/clip-vit-base-patch32"` | é¢„è®­ç»ƒæ¨¡å‹åç§° |

### å¯ç”¨æ¨¡å‹

- `"openai/clip-vit-base-patch32"` (é»˜è®¤) - CLIP Base
- `"openai/clip-vit-large-patch14"` - CLIP Largeï¼ˆæ›´å¤§ï¼Œæ›´æ…¢ï¼‰

## ğŸ”§ ä¼˜åŒ–å™¨é…ç½® (`optimizer`)

### å‚æ•°è¯´æ˜

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `type` | str | `"adamw"` | ä¼˜åŒ–å™¨ç±»å‹ï¼ˆå½“å‰ä»…æ”¯æŒ AdamWï¼‰ |
| `weight_decay` | float | `0.01` | æƒé‡è¡°å‡ |
| `betas` | list | `[0.9, 0.999]` | Adam çš„ beta å‚æ•° |

### é…ç½®ç¤ºä¾‹

```yaml
optimizer:
  type: "adamw"
  weight_decay: 0.01
  betas: [0.9, 0.999]
```

## ğŸ“ˆ å­¦ä¹ ç‡è°ƒåº¦å™¨é…ç½® (`lr_scheduler`)

### å‚æ•°è¯´æ˜

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `type` | str | `"cosine"` | è°ƒåº¦å™¨ç±»å‹ï¼ˆå½“å‰ä»…æ”¯æŒ cosineï¼‰ |
| `warmup_steps` | int | `500` | é¢„çƒ­æ­¥æ•° |

### å­¦ä¹ ç‡å˜åŒ–

- **å‰ `warmup_steps` æ­¥**: çº¿æ€§å¢åŠ åˆ° `learning_rate`
- **ä¹‹å**: ä½™å¼¦é€€ç«åˆ° 0

## ğŸ“ å®Œæ•´é…ç½®ç¤ºä¾‹

### RTX 4090 ä¼˜åŒ–é…ç½®ï¼ˆå½“å‰ï¼‰

```yaml
data:
  dataset_name: "cub"
  dataset_path: "./data/cub_subset"
  image_size: 256
  num_samples: 5000

model:
  hidden_size: 768
  num_layers: 16
  num_heads: 12
  patch_size: 2
  in_channels: 4
  out_channels: 4
  attention_head_dim: 64
  mlp_ratio: 4.0
  dropout: 0.1

vae:
  pretrained_model_name: "runwayml/stable-diffusion-v1-5"
  use_slicing: false

training:
  output_dir: "./outputs"
  seed: 42
  batch_size: 96
  gradient_accumulation_steps: 1
  learning_rate: 0.0001
  num_epochs: 1000
  save_every_n_epochs: 10
  logging_steps: 50
  mixed_precision: "bf16"
  max_grad_norm: 1.0
  use_ema: false
  num_workers: 8
  prefetch_factor: 4
  compile_model: false

scheduler:
  num_train_timesteps: 1000
  beta_start: 0.00085
  beta_end: 0.012
  beta_schedule: "scaled_linear"
  prediction_type: "epsilon"

text_encoder:
  pretrained_model_name: "openai/clip-vit-base-patch32"

optimizer:
  type: "adamw"
  weight_decay: 0.01
  betas: [0.9, 0.999]

lr_scheduler:
  type: "cosine"
  warmup_steps: 500
```

## ğŸ” é…ç½®éªŒè¯

### æ£€æŸ¥é…ç½®

```python
from src.utils.config import load_config

config = load_config("configs/train_config.yaml")
print(config.to_dict())
```

### å¸¸è§é…ç½®é”™è¯¯

1. **`num_heads` ä¸æ˜¯ `hidden_size` çš„çº¦æ•°**
   - é”™è¯¯: `hidden_size: 768, num_heads: 13`
   - æ­£ç¡®: `hidden_size: 768, num_heads: 12` (768 % 12 == 0)

2. **`image_size` ä¸æ˜¯ 8 çš„å€æ•°**
   - é”™è¯¯: `image_size: 250`
   - æ­£ç¡®: `image_size: 256` (256 % 8 == 0)

3. **`batch_size` è¿‡å¤§å¯¼è‡´æ˜¾å­˜ä¸è¶³**
   - è§£å†³æ–¹æ¡ˆ: å‡å° `batch_size`ï¼Œå¢åŠ  `gradient_accumulation_steps`

## ğŸ“ ä¸‹ä¸€æ­¥

- ğŸ“– [05. è®­ç»ƒæŒ‡å—](./05-è®­ç»ƒæŒ‡å—.md) - äº†è§£è®­ç»ƒæµç¨‹
- ğŸ“– [08. æ•…éšœæ’é™¤](./08-æ•…éšœæ’é™¤.md) - é…ç½®ç›¸å…³é—®é¢˜

---

**é…ç½®å®Œæˆ**: æ ¹æ®ä½ çš„ç¡¬ä»¶å’Œéœ€æ±‚è°ƒæ•´é…ç½®å‚æ•°ï¼

