# 08. æ•…éšœæ’é™¤

æœ¬æŒ‡å—æ•´ç†æ‰€æœ‰å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆï¼ŒåŸºäºå®é™…ä»£ç å’Œå·²çŸ¥é—®é¢˜ã€‚

## ğŸ” é—®é¢˜åˆ†ç±»

- [ç½‘ç»œé—®é¢˜](#ç½‘ç»œé—®é¢˜)
- [æ˜¾å­˜é—®é¢˜](#æ˜¾å­˜é—®é¢˜)
- [æ•°æ®é—®é¢˜](#æ•°æ®é—®é¢˜)
- [è®­ç»ƒé—®é¢˜](#è®­ç»ƒé—®é¢˜)
- [æ¨ç†é—®é¢˜](#æ¨ç†é—®é¢˜)
- [é…ç½®é—®é¢˜](#é…ç½®é—®é¢˜)

## ğŸŒ ç½‘ç»œé—®é¢˜

### é—®é¢˜ 1: Hugging Face ä¸‹è½½è¶…æ—¶

**ç—‡çŠ¶**:
```
ReadTimeoutError: HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)
```

**åŸå› **: é»˜è®¤è¶…æ—¶æ—¶é—´å¤ªçŸ­ï¼ˆ10ç§’ï¼‰ï¼Œç½‘ç»œè¾ƒæ…¢æ—¶å®¹æ˜“è¶…æ—¶

**è§£å†³æ–¹æ¡ˆ**:

#### æ–¹æ³• 1: ä½¿ç”¨é•œåƒï¼ˆæ¨èï¼‰

```bash
export HF_ENDPOINT=https://hf-mirror.com
export HF_HUB_DOWNLOAD_TIMEOUT=600
python src/scripts/train.py --config configs/train_config.yaml
```

#### æ–¹æ³• 2: ä½¿ç”¨ä»£ç†

```bash
export HTTP_PROXY=http://127.0.0.1:7890
export HTTPS_PROXY=http://127.0.0.1:7890
export HF_HUB_DOWNLOAD_TIMEOUT=600
python src/scripts/train.py --config configs/train_config.yaml
```

#### æ–¹æ³• 3: ä½¿ç”¨è„šæœ¬

```bash
source setup_hf_mirror.sh  # æˆ– setup_proxy.sh
python src/scripts/train.py --config configs/train_config.yaml
```

**ä»£ç ä½ç½®**: 
- `src/scripts/train.py` (ç¬¬ 146 è¡Œ): å·²è®¾ç½® `HF_HUB_DOWNLOAD_TIMEOUT=600`
- `src/models/vae_model.py` (ç¬¬ 10 è¡Œ): å·²è®¾ç½®è¶…æ—¶

### é—®é¢˜ 2: æ•°æ®é›†ä¸‹è½½å¤±è´¥

**ç—‡çŠ¶**: COCO æˆ– CUB æ•°æ®é›†ä¸‹è½½å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**:

#### COCO æ•°æ®é›†
- æ‰‹åŠ¨ä¸‹è½½: è®¿é—® https://cocodataset.org/
- ä½¿ç”¨è„šæœ¬: `python src/scripts/prepare_coco_from_download.py`

#### CUB æ•°æ®é›†
- ä» Kaggle ä¸‹è½½: ä½¿ç”¨ `kagglehub`
- ä½¿ç”¨è„šæœ¬: `python src/scripts/prepare_cub_from_kaggle.py`

## ğŸ’¾ æ˜¾å­˜é—®é¢˜

### é—®é¢˜ 1: CUDA Out of Memory

**ç—‡çŠ¶**:
```
RuntimeError: CUDA out of memory. Tried to allocate X GiB.
```

**åŸå› **: æ‰¹æ¬¡å¤§å°æˆ–æ¨¡å‹å¤ªå¤§ï¼Œè¶…å‡º GPU æ˜¾å­˜

**è§£å†³æ–¹æ¡ˆ**:

#### æ–¹æ³• 1: å‡å°æ‰¹æ¬¡å¤§å°

```yaml
training:
  batch_size: 32  # ä» 96 å‡å°åˆ° 32
  gradient_accumulation_steps: 3  # ä¿æŒæœ‰æ•ˆæ‰¹æ¬¡å¤§å°
```

#### æ–¹æ³• 2: å¯ç”¨ VAE åˆ‡ç‰‡

```yaml
vae:
  use_slicing: true  # èŠ‚çœæ˜¾å­˜
```

#### æ–¹æ³• 3: ä½¿ç”¨æ›´å°çš„æ¨¡å‹

```yaml
model:
  hidden_size: 384  # ä» 768 å‡å°åˆ° 384
  num_layers: 8      # ä» 16 å‡å°åˆ° 8
```

#### æ–¹æ³• 4: å…³é—­æ¨¡å‹ç¼–è¯‘

```yaml
training:
  compile_model: false  # å…³é—­ torch.compile
```

### é—®é¢˜ 2: æ˜¾å­˜åˆ©ç”¨ç‡ä½

**ç—‡çŠ¶**: GPU æ˜¾å­˜ä½¿ç”¨ç‡ < 50%

**è§£å†³æ–¹æ¡ˆ**:

```yaml
training:
  batch_size: 96              # å¢åŠ æ‰¹æ¬¡å¤§å°
  num_workers: 8              # å¢åŠ æ•°æ®åŠ è½½çº¿ç¨‹
  prefetch_factor: 4          # å¢åŠ é¢„å–å› å­
  persistent_workers: true    # ä¿æŒå·¥ä½œè¿›ç¨‹
```

## ğŸ“Š æ•°æ®é—®é¢˜

### é—®é¢˜ 1: æ•°æ®é›†åŠ è½½å¤±è´¥

**ç—‡çŠ¶**:
```
ValueError: ä¸æ”¯æŒçš„æ•°æ®é›†: xxx
```

**åŸå› **: `dataset_name` é…ç½®é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**:
- æ£€æŸ¥ `dataset_name` æ˜¯å¦ä¸º `"coco"`, `"cub"` æˆ– `"custom"`
- æ£€æŸ¥ `dataset_path` æ˜¯å¦å­˜åœ¨
- æ£€æŸ¥ `metadata.json` æ ¼å¼æ˜¯å¦æ­£ç¡®

**ä»£ç ä½ç½®**: `src/data/dataset.py` (ç¬¬ 65 è¡Œ)

### é—®é¢˜ 2: å›¾åƒåŠ è½½å¤±è´¥

**ç—‡çŠ¶**:
```
FileNotFoundError: [Errno 2] No such file or directory: 'xxx.jpg'
```

**åŸå› **: å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨æˆ–è·¯å¾„é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**:
- æ£€æŸ¥å›¾åƒæ–‡ä»¶æ˜¯å¦å­˜åœ¨
- æ£€æŸ¥ `metadata.json` ä¸­çš„è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
- éªŒè¯å›¾åƒæ–‡ä»¶æ˜¯å¦æŸå

### é—®é¢˜ 3: ç”Ÿæˆå›¾åƒæ˜¯ç°è‰²çš„

**ç—‡çŠ¶**: ç”Ÿæˆçš„å›¾åƒå…¨æ˜¯ç°è‰²ï¼Œæ²¡æœ‰é¢œè‰²

**åŸå› **: æ½œåœ¨ç©ºé—´ç¼©æ”¾å› å­æœªæ­£ç¡®åº”ç”¨

**è§£å†³æ–¹æ¡ˆ**: å·²ä¿®å¤
- æ£€æŸ¥ `src/inference/generator.py` (ç¬¬ 135-136 è¡Œ) æ˜¯å¦åŒ…å« `scaling_factor` åº”ç”¨
- ç¡®ä¿ä½¿ç”¨æœ€æ–°ä»£ç 

**ä»£ç ä½ç½®**: `src/inference/generator.py` (ç¬¬ 135-136 è¡Œ)

## ğŸ‹ï¸ è®­ç»ƒé—®é¢˜

### é—®é¢˜ 1: è®­ç»ƒä¸­æ–­

**ç—‡çŠ¶**: è®­ç»ƒè¿‡ç¨‹ä¸­æ–­ï¼Œéœ€è¦æ¢å¤

**è§£å†³æ–¹æ¡ˆ**:

```bash
python src/scripts/train.py \
    --config configs/train_config.yaml \
    --resume ./outputs/checkpoint-epoch-10
```

**ä»£ç ä½ç½®**: `src/training/trainer.py` (load_checkpoint æ–¹æ³•)

### é—®é¢˜ 2: Loss ä¸ä¸‹é™

**ç—‡çŠ¶**: è®­ç»ƒ Loss ä¸€ç›´å¾ˆé«˜ï¼Œä¸ä¸‹é™

**å¯èƒ½åŸå› **:
1. å­¦ä¹ ç‡è¿‡å¤§æˆ–è¿‡å°
2. æ•°æ®è´¨é‡é—®é¢˜
3. æ¨¡å‹é…ç½®ä¸å½“

**è§£å†³æ–¹æ¡ˆ**:

#### è°ƒæ•´å­¦ä¹ ç‡

```yaml
training:
  learning_rate: 0.0001  # å°è¯• 1e-4, 2e-4, 5e-5
```

#### æ£€æŸ¥æ•°æ®è´¨é‡

```python
# æ£€æŸ¥æ•°æ®
from src.data.dataset import TextImageDataset
dataset = TextImageDataset(...)
print(f"æ ·æœ¬æ•°: {len(dataset)}")
print(f"ç¬¬ä¸€ä¸ªæ ·æœ¬: {dataset[0]}")
```

#### ä½¿ç”¨é¢„è®­ç»ƒæƒé‡ï¼ˆå¦‚æœæœ‰ï¼‰

### é—®é¢˜ 3: æ£€æŸ¥ç‚¹ä¿å­˜å¤±è´¥

**ç—‡çŠ¶**:
```
RuntimeError: PytorchStreamWriter failed writing file
```

**åŸå› **: ç£ç›˜ç©ºé—´ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**:
- æ¸…ç†æ—§æ£€æŸ¥ç‚¹: `bash auto_cleanup_checkpoints.sh`
- å¢åŠ ä¿å­˜é—´éš”: `save_every_n_epochs: 10`
- æ£€æŸ¥ç£ç›˜ç©ºé—´: `df -h`

**ä»£ç ä½ç½®**: `src/training/trainer.py` (save_checkpoint æ–¹æ³•ï¼Œå·²æ·»åŠ é”™è¯¯å¤„ç†)

### é—®é¢˜ 4: æ–­ç‚¹ç»­ä¼ å¤±è´¥

**ç—‡çŠ¶**:
```
RuntimeError: Error(s) in loading state_dict: Missing key(s)...
```

**åŸå› **: æ¨¡å‹ç»“æ„å˜åŒ–æˆ– `torch.compile` å¯¼è‡´çš„é”®åä¸åŒ¹é…

**è§£å†³æ–¹æ¡ˆ**:

#### æ–¹æ³• 1: ç¦ç”¨æ¨¡å‹ç¼–è¯‘

```yaml
training:
  compile_model: false  # æ–­ç‚¹ç»­ä¼ æ—¶ç¦ç”¨
```

#### æ–¹æ³• 2: ä»£ç å·²å¤„ç†

ä»£ç å·²è‡ªåŠ¨å¤„ç† `_orig_mod.` å‰ç¼€ï¼ˆ`src/scripts/inference.py` ç¬¬ 150-158 è¡Œï¼‰

### é—®é¢˜ 5: æŸåçš„æ£€æŸ¥ç‚¹æ–‡ä»¶

**ç—‡çŠ¶**:
```
RuntimeError: PytorchStreamReader failed reading zip archive
```

**åŸå› **: æ£€æŸ¥ç‚¹æ–‡ä»¶æŸåï¼ˆå¯èƒ½ç”±äºç£ç›˜ç©ºé—´ä¸è¶³æˆ–ä¸­æ–­ï¼‰

**è§£å†³æ–¹æ¡ˆ**:
- åˆ é™¤æŸåçš„æ–‡ä»¶: `rm outputs/checkpoint-epoch-X/optimizer.pt`
- ä»£ç å·²æ·»åŠ é”™è¯¯å¤„ç†ï¼Œä¼šè‡ªåŠ¨è·³è¿‡æŸåçš„æ–‡ä»¶

**ä»£ç ä½ç½®**: `src/training/trainer.py` (load_checkpoint æ–¹æ³•ï¼Œå·²æ·»åŠ  try-except)

## ğŸ¨ æ¨ç†é—®é¢˜

### é—®é¢˜ 1: ç”Ÿæˆé€Ÿåº¦æ…¢

**ç—‡çŠ¶**: ç”Ÿæˆä¸€å¼ å›¾åƒéœ€è¦å¾ˆé•¿æ—¶é—´

**è§£å†³æ–¹æ¡ˆ**:
- å‡å°‘æ¨ç†æ­¥æ•°: `--num_inference_steps 30`
- ä½¿ç”¨è¾ƒå°çš„å›¾åƒå°ºå¯¸: `--height 256 --width 256`
- ç¡®ä¿ä½¿ç”¨ GPU: `nvidia-smi`

### é—®é¢˜ 2: ç”Ÿæˆè´¨é‡å·®

**ç—‡çŠ¶**: ç”Ÿæˆçš„å›¾åƒè´¨é‡ä¸å¥½

**å¯èƒ½åŸå› **:
1. æ¨¡å‹è®­ç»ƒä¸å……åˆ†
2. æç¤ºè¯ä¸åˆé€‚
3. æ¨ç†æ­¥æ•°å¤ªå°‘

**è§£å†³æ–¹æ¡ˆ**:
- ç»§ç»­è®­ç»ƒæ¨¡å‹ï¼ˆæ›´å¤š epochsï¼‰
- ä¼˜åŒ–æç¤ºè¯ï¼ˆæ›´å…·ä½“ã€è¯¦ç»†ï¼‰
- å¢åŠ æ¨ç†æ­¥æ•°: `--num_inference_steps 100`

### é—®é¢˜ 3: ç”Ÿæˆå›¾åƒä¸æç¤ºä¸ç¬¦

**ç—‡çŠ¶**: ç”Ÿæˆçš„å›¾åƒä¸ç¬¦åˆæ–‡æœ¬æè¿°

**è§£å†³æ–¹æ¡ˆ**:
- å¢åŠ å¼•å¯¼å¼ºåº¦: `guidance_scale: 10-15`
- ä¼˜åŒ–æç¤ºè¯ï¼ˆæ›´æ¸…æ™°ã€å…·ä½“ï¼‰
- æ£€æŸ¥æ¨¡å‹è®­ç»ƒæ˜¯å¦å……åˆ†

## âš™ï¸ é…ç½®é—®é¢˜

### é—®é¢˜ 1: é…ç½®å‚æ•°é”™è¯¯

**ç—‡çŠ¶**:
```
ValueError: num_heads must divide hidden_size
```

**åŸå› **: `num_heads` ä¸æ˜¯ `hidden_size` çš„çº¦æ•°

**è§£å†³æ–¹æ¡ˆ**:
```yaml
model:
  hidden_size: 768
  num_heads: 12  # 768 % 12 == 0 âœ…
  # num_heads: 13  # 768 % 13 != 0 âŒ
```

### é—®é¢˜ 2: å›¾åƒå°ºå¯¸é”™è¯¯

**ç—‡çŠ¶**: VAE ç¼–ç /è§£ç å¤±è´¥

**åŸå› **: `image_size` ä¸æ˜¯ 8 çš„å€æ•°

**è§£å†³æ–¹æ¡ˆ**:
```yaml
data:
  image_size: 256  # 256 % 8 == 0 âœ…
  # image_size: 250  # 250 % 8 != 0 âŒ
```

### é—®é¢˜ 3: æ‰¹æ¬¡å¤§å°é…ç½®é”™è¯¯

**ç—‡çŠ¶**: æ˜¾å­˜ä¸è¶³æˆ–åˆ©ç”¨ç‡ä½

**è§£å†³æ–¹æ¡ˆ**: æ ¹æ® GPU æ˜¾å­˜è°ƒæ•´

```yaml
# RTX 4090 (24GB)
training:
  batch_size: 96

# RTX 3090 (24GB)
training:
  batch_size: 64

# RTX 3080 (10GB)
training:
  batch_size: 16
  gradient_accumulation_steps: 4
```

## ğŸ—‚ï¸ ç£ç›˜ç©ºé—´é—®é¢˜

### é—®é¢˜ 1: ä¸´æ—¶ç›®å½•é”™è¯¯

**ç—‡çŠ¶**:
```
FileNotFoundError: [Errno 2] No usable temporary directory found
```

**åŸå› **: ç³»ç»Ÿä¸´æ—¶ç›®å½•ä¸å¯ç”¨æˆ–ç£ç›˜ç©ºé—´ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**: ä»£ç å·²è‡ªåŠ¨å¤„ç†
- è‡ªåŠ¨ä½¿ç”¨ `./outputs/tmp` ä½œä¸ºä¸´æ—¶ç›®å½•
- æ£€æŸ¥ç£ç›˜ç©ºé—´: `df -h`

**ä»£ç ä½ç½®**: `src/scripts/train.py` (ç¬¬ 19-43 è¡Œ)

### é—®é¢˜ 2: ç£ç›˜ç©ºé—´ä¸è¶³

**ç—‡çŠ¶**: æ£€æŸ¥ç‚¹ä¿å­˜å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**:
- æ¸…ç†æ—§æ£€æŸ¥ç‚¹: `bash auto_cleanup_checkpoints.sh`
- å¢åŠ ä¿å­˜é—´éš”: `save_every_n_epochs: 10`
- åˆ é™¤ä¸éœ€è¦çš„æ–‡ä»¶

## ğŸ”§ ä»£ç é—®é¢˜

### é—®é¢˜ 1: å¯¼å…¥é”™è¯¯

**ç—‡çŠ¶**:
```
ImportError: attempted relative import with no known parent package
```

**åŸå› **: ç›´æ¥è¿è¡Œè„šæœ¬æ—¶ç›¸å¯¹å¯¼å…¥å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**: å·²ä¿®å¤
- æ‰€æœ‰è„šæœ¬å·²æ”¹ä¸ºç»å¯¹å¯¼å…¥
- æ·»åŠ äº† `sys.path.insert` æ”¯æŒç›´æ¥è¿è¡Œ

**ä»£ç ä½ç½®**: æ‰€æœ‰ `src/scripts/*.py` æ–‡ä»¶

### é—®é¢˜ 2: æ¨¡å—æœªæ‰¾åˆ°

**ç—‡çŠ¶**:
```
ModuleNotFoundError: No module named 'xxx'
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
pip install -r requirements.txt
```

## ğŸ“ è°ƒè¯•æŠ€å·§

### 1. å¯ç”¨è¯¦ç»†æ—¥å¿—

```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

### 2. æ£€æŸ¥ GPU çŠ¶æ€

```bash
nvidia-smi
watch -n 1 nvidia-smi  # å®æ—¶ç›‘æ§
```

### 3. éªŒè¯æ•°æ®

```python
from src.data.dataset import TextImageDataset
dataset = TextImageDataset(...)
print(f"æ•°æ®é›†å¤§å°: {len(dataset)}")
item = dataset[0]
print(f"å›¾åƒå½¢çŠ¶: {item['pixel_values'].shape}")
print(f"æ–‡æœ¬: {item['text']}")
```

### 4. æ£€æŸ¥æ¨¡å‹

```python
from src.models.dit_model import DiTModel
model = DiTModel(...)
print(f"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters())}")
```

## ğŸ“ è·å–å¸®åŠ©

å¦‚æœä»¥ä¸Šæ–¹æ¡ˆéƒ½æ— æ³•è§£å†³é—®é¢˜ï¼š

1. æ£€æŸ¥æ—¥å¿—æ–‡ä»¶: `./outputs/train.log`
2. æŸ¥çœ‹é”™è¯¯å †æ ˆä¿¡æ¯
3. æ£€æŸ¥ä»£ç ç‰ˆæœ¬æ˜¯å¦æœ€æ–°
4. æäº¤ Issueï¼ˆåŒ…å«é”™è¯¯ä¿¡æ¯å’Œç¯å¢ƒä¿¡æ¯ï¼‰

## ğŸ“ ä¸‹ä¸€æ­¥

- ğŸ“– [01. å¿«é€Ÿå¼€å§‹](./01-å¿«é€Ÿå¼€å§‹.md) - é‡æ–°å¼€å§‹
- ğŸ“– [07. é…ç½®å‚è€ƒ](./07-é…ç½®å‚è€ƒ.md) - æ£€æŸ¥é…ç½®

---

**é—®é¢˜è§£å†³**: å¦‚æœé—®é¢˜ä»æœªè§£å†³ï¼Œè¯·æ£€æŸ¥æ—¥å¿—æ–‡ä»¶è·å–æ›´å¤šä¿¡æ¯ï¼

