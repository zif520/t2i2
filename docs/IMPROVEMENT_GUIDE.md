# 图像质量提升完整指南

## 🎯 目标

将生成的图像从当前的"有颜色但质量一般"提升到"高质量、清晰、符合文本描述"。

## 📊 当前状态分析

### 训练状态
- **Epochs**: 200（已完成）
- **数据集**: 合成数据（5000样本）
- **损失**: 0.006-0.008（理想: 0.001-0.003）
- **图像质量**: 有颜色但细节不足

### 问题诊断
1. **训练不充分**: 损失值偏高，模型还未完全收敛
2. **数据质量**: 使用合成数据，缺乏真实图像的多样性
3. **数据量**: 5000样本对于扩散模型来说偏少

## 🚀 改进方案（按优先级）

### 方案1: 继续训练当前模型（最简单）⭐⭐⭐

**适用场景**: 想快速改善，不想换数据集

**步骤**:
1. 继续训练到 400-500 epochs
2. 监控损失，如果不再下降则停止

**具体操作**:
```bash
# 修改配置
# configs/train_config.yaml
training:
  num_epochs: 500  # 从 200 增加到 500

# 继续训练（断点续传）
python src/scripts/train.py \
    --config configs/train_config.yaml \
    --resume ./outputs/checkpoint-epoch-200
```

**预期效果**:
- 损失降到 0.002-0.004
- 图像质量提升 30-50%
- 需要时间: 10-15 小时（RTX 4090）

**优点**: 
- ✅ 不需要重新准备数据
- ✅ 可以立即开始
- ✅ 成本低

**缺点**:
- ⚠️ 提升有限（受数据质量限制）
- ⚠️ 可能无法达到最佳效果

---

### 方案2: 使用真实数据集（推荐）⭐⭐⭐⭐⭐

**适用场景**: 想要最佳效果，愿意花时间准备数据

#### 2.1 推荐数据集

##### 选项A: COCO 2017（最推荐）

**特点**:
- 12万张图像，每张都有文本描述
- 高质量、多样性好
- 广泛用于文生图训练

**下载和使用**:
```bash
# 方法1: 使用 Hugging Face datasets（推荐）
# 代码已支持，只需修改配置

# configs/train_config.yaml
data:
  dataset_name: "detection-datasets/coco_2017_val_panoptic"  # 或使用其他 COCO 变体
  dataset_path: "./data/coco"
  num_samples: null  # null 表示使用全部数据
  image_size: 256
  train_split: 0.9
```

**数据量建议**:
- **最小**: 10,000 张（快速测试）
- **推荐**: 50,000-100,000 张（最佳效果）
- **理想**: 100,000+ 张（接近 SOTA）

##### 选项B: LAION-400M 子集

**特点**:
- 4亿张图像（可用子集）
- 质量高，描述详细
- 需要更多存储空间

**使用**:
```bash
# 需要下载 LAION 数据集
# 建议使用 10,000-50,000 张作为开始
```

##### 选项C: 自定义数据集

**适用场景**: 有特定领域需求

**要求**:
- 图像尺寸: 256x256 或更大（会自动resize）
- 格式: JPG/PNG
- 文本描述: 每张图像一个文本文件或 JSON

**准备步骤**:
1. 收集图像和对应的文本描述
2. 组织成以下结构:
```
data/custom/
  images/
    image1.jpg
    image2.jpg
    ...
  captions.json  # {"image1.jpg": "a cat", "image2.jpg": "a dog", ...}
```

#### 2.2 使用真实数据的训练配置

```yaml
# configs/train_config.yaml
data:
  dataset_name: "coco"  # 或 "custom"
  dataset_path: "./data/coco"
  num_samples: null  # 使用全部数据
  image_size: 256
  train_split: 0.9

training:
  num_epochs: 300  # 真实数据通常需要更少 epochs
  batch_size: 96
  learning_rate: 0.0001
  # ... 其他配置保持不变
```

**预期效果**:
- 损失降到 0.001-0.002
- 图像质量显著提升（50-100%）
- 更好的文本对齐
- 需要时间: 15-20 小时（50K 样本，RTX 4090）

---

### 方案3: 混合方案（平衡）⭐⭐⭐⭐

**适用场景**: 想要好效果但时间有限

**步骤**:
1. 先用真实数据集训练 200 epochs
2. 如果效果不够，继续训练到 300-400 epochs

**数据量**: 20,000-50,000 张真实图像

**时间成本**: 10-15 小时

---

## 📈 Epoch 数量建议

### 基于数据量

| 数据量 | 推荐 Epochs | 说明 |
|--------|------------|------|
| 5,000 样本 | 500-800 | 小数据集需要更多 epochs |
| 10,000 样本 | 300-500 | 中等数据集 |
| 50,000 样本 | 200-300 | 大数据集，收敛更快 |
| 100,000+ 样本 | 150-250 | 大数据集，通常 200 足够 |

### 基于损失值

**停止训练的标准**:
- 损失 < 0.002 且不再下降 → 可以停止
- 损失在 0.002-0.004 且持续下降 → 继续训练
- 损失 > 0.004 → 需要更多训练或调整学习率

**监控方法**:
```bash
# 训练过程中观察损失
# 如果连续 20 epochs 损失不再下降，可以考虑停止
```

---

## 🛠️ 具体操作步骤

### 步骤1: 选择数据集

**快速测试（推荐先做）**:
```bash
# 继续训练当前模型到 400 epochs
# 修改 configs/train_config.yaml
training:
  num_epochs: 400

# 继续训练
python src/scripts/train.py \
    --config configs/train_config.yaml \
    --resume ./outputs/checkpoint-epoch-200
```

**最佳效果（推荐）**:
```bash
# 1. 准备 COCO 数据集
# 代码已支持，但需要确保网络可以下载
# 或者手动下载后放到 ./data/coco/

# 2. 修改配置
# configs/train_config.yaml
data:
  dataset_name: "coco"
  num_samples: 50000  # 使用 5 万张图像
  # 或 num_samples: null  # 使用全部

# 3. 重新训练（从头开始）
python src/scripts/train.py \
    --config configs/train_config.yaml
```

### 步骤2: 监控训练

**关键指标**:
1. **损失值**: 应该持续下降
2. **生成质量**: 每 50 epochs 生成一张测试图像
3. **训练时间**: 估算剩余时间

**检查点**:
- 每 10 epochs 保存一次（已配置）
- 定期生成测试图像查看效果

### 步骤3: 调整参数（如果需要）

**如果损失不再下降**:
```yaml
training:
  learning_rate: 0.00005  # 从 0.0001 减半
  # 或使用学习率调度器
```

**如果显存不足**:
```yaml
training:
  batch_size: 64  # 从 96 减少
  gradient_accumulation_steps: 2  # 保持有效批次大小
```

---

## ⏱️ 时间估算（RTX 4090）

### 方案1: 继续训练（200 → 500 epochs）
- **时间**: 10-15 小时
- **数据**: 现有 5000 样本
- **预期提升**: 30-50%

### 方案2: 真实数据（50K 样本，300 epochs）
- **数据准备**: 1-2 小时（下载）
- **训练时间**: 15-20 小时
- **预期提升**: 50-100%

### 方案3: 真实数据（100K 样本，200 epochs）
- **数据准备**: 2-3 小时（下载）
- **训练时间**: 20-25 小时
- **预期提升**: 80-150%

---

## 🎯 推荐方案

### 短期（1-2天）: 方案1
- 继续训练到 400-500 epochs
- 快速改善，成本低
- 预期: 图像质量提升 30-50%

### 中期（2-3天）: 方案2（50K COCO）
- 使用真实数据集
- 训练 300 epochs
- 预期: 图像质量提升 50-100%

### 长期（3-5天）: 方案2（100K+ COCO）
- 使用更多真实数据
- 训练 200-300 epochs
- 预期: 接近 SOTA 质量

---

## 📝 检查清单

### 开始训练前
- [ ] 确认数据集路径正确
- [ ] 检查磁盘空间（至少 50GB 可用）
- [ ] 确认 GPU 显存充足（24GB RTX 4090 足够）
- [ ] 备份当前检查点

### 训练过程中
- [ ] 监控损失值（应该持续下降）
- [ ] 定期生成测试图像（每 50 epochs）
- [ ] 检查磁盘空间（检查点会占用空间）
- [ ] 记录训练日志

### 训练完成后
- [ ] 验证最终损失值（应该 < 0.003）
- [ ] 生成多张测试图像
- [ ] 评估图像质量
- [ ] 如果不够好，考虑继续训练或调整参数

---

## 🔧 故障排除

### 问题1: 数据集下载失败
**解决**: 
- 使用镜像站点
- 手动下载后放到指定目录
- 检查网络连接

### 问题2: 显存不足
**解决**:
- 减小 batch_size
- 增加 gradient_accumulation_steps
- 使用 VAE slicing（已启用）

### 问题3: 损失不下降
**解决**:
- 减小学习率（减半）
- 检查数据质量
- 增加训练 epochs

---

## 📚 参考资源

- COCO 数据集: https://cocodataset.org/
- LAION 数据集: https://laion.ai/
- Hugging Face Datasets: https://huggingface.co/datasets

---

**建议**: 先从方案1开始（继续训练），如果效果不够再考虑方案2（真实数据）。

