# DiT 文生图教程文档

欢迎来到 DiT (Diffusion Transformer) 文生图教程！本教程将帮助你从零开始学习如何使用 Transformer 架构的扩散模型进行文本到图像的生成。

## 🚀 快速开始

**5 分钟快速上手：** [快速开始指南](./QUICK_START.md)

**完整教程：** [完整教程](./00-完整教程.md)

## 📚 文档导航

### 🎯 核心教程

- **[完整教程](./00-完整教程.md)** ⭐ - 完整学习路径，包含所有内容
- **[快速开始](./QUICK_START.md)** ⭐ - 5分钟快速上手

### 📖 基础篇

1. **[入门指南](./01-入门指南.md)** - 了解文生图和 DiT 的基础概念
2. **[环境配置](./02-环境配置.md)** - 安装和配置开发环境
3. **[数据准备](./03-数据准备.md)** - 准备训练数据集

### 🔧 进阶篇

4. **[模型架构](./04-模型架构.md)** - 深入理解 DiT 模型结构
5. **[训练流程](./05-训练流程.md)** - 完整的训练步骤和技巧
6. **[推理使用](./06-推理使用.md)** - 使用训练好的模型生成图像

### 📚 参考篇

7. **[常见问题](./07-常见问题.md)** - FAQ 和故障排除
8. **[进阶学习](./08-进阶学习.md)** - 进阶内容和扩展方向

## 🚀 快速开始

如果你已经熟悉相关概念，可以按照以下步骤快速开始：

1. **安装环境** - 参考 [环境配置](./02-环境配置.md)
2. **准备数据** - 参考 [数据准备](./03-数据准备.md)
3. **开始训练** - 参考 [训练流程](./05-训练流程.md)
4. **生成图像** - 参考 [推理使用](./06-推理使用.md)

## 📖 学习路径

### 初学者路径

1. 阅读 [入门指南](./01-入门指南.md) 了解基本概念
2. 按照 [环境配置](./02-环境配置.md) 搭建环境
3. 使用示例数据运行训练，参考 [训练流程](./05-训练流程.md)
4. 尝试生成图像，参考 [推理使用](./06-推理使用.md)

### 进阶路径

1. 深入理解 [模型架构](./04-模型架构.md)
2. 优化训练参数，参考 [训练流程](./05-训练流程.md)
3. 解决遇到的问题，参考 [常见问题](./07-常见问题.md)
4. 探索进阶内容，参考 [进阶学习](./08-进阶学习.md)

## 💡 项目特点

- ✅ **基于 Hugging Face** - 使用标准化的 Hugging Face 库
- ✅ **小模型配置** - 适配 RTX 4090，使用小模型和小数据集
- ✅ **完整可运行** - 确保能够成功训练和生成
- ✅ **详细文档** - 每个步骤都有详细说明
- ✅ **易于学习** - 代码注释清晰，结构模块化

## 🛠️ 技术栈

- **PyTorch** - 深度学习框架
- **Hugging Face Diffusers** - 扩散模型库
- **Hugging Face Transformers** - Transformer 模型库
- **Hugging Face Accelerate** - 训练加速
- **Hugging Face Datasets** - 数据集管理

## 📝 注意事项

1. 本项目使用小模型配置，适合学习和实验
2. 训练需要 GPU（推荐 RTX 4090 或更高）
3. 首次运行会下载预训练模型（VAE、文本编码器等）
4. 建议先使用小数据集进行测试

## 🤝 贡献

如果你发现任何问题或有改进建议，欢迎提出 Issue 或 Pull Request。

## 📄 许可证

本项目采用 Apache 2.0 许可证。

---

**祝你学习愉快！** 🎉



