# æ–­ç‚¹ç»­ä¼ è®­ç»ƒæŒ‡å—

## ğŸ“‹ åŠŸèƒ½è¯´æ˜

é¡¹ç›®å·²æ”¯æŒå®Œæ•´çš„æ–­ç‚¹ç»­ä¼ åŠŸèƒ½ï¼Œå¯ä»¥ä»ä»»æ„æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒï¼ŒåŒ…æ‹¬ï¼š
- âœ… æ¨¡å‹æƒé‡
- âœ… ä¼˜åŒ–å™¨çŠ¶æ€
- âœ… å­¦ä¹ ç‡è°ƒåº¦å™¨çŠ¶æ€
- âœ… è®­ç»ƒè¿›åº¦ï¼ˆepochã€stepï¼‰
- âœ… EMA æ¨¡å‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬ç”¨æ³•

```bash
# ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ
python src/scripts/train.py \
    --config configs/train_config.yaml \
    --resume ./outputs/checkpoint-epoch-118
```

### ä½¿ç”¨å¯åŠ¨è„šæœ¬

```bash
# ä½¿ç”¨å¯åŠ¨è„šæœ¬æ¢å¤è®­ç»ƒ
./run_train.sh \
    --config configs/train_config.yaml \
    --resume ./outputs/checkpoint-epoch-118
```

## ğŸ“ æ£€æŸ¥ç‚¹ç»“æ„

æ¯ä¸ªæ£€æŸ¥ç‚¹ç›®å½•åŒ…å«ä»¥ä¸‹æ–‡ä»¶ï¼š

```
checkpoint-epoch-118/
â”œâ”€â”€ model.pt              # æ¨¡å‹æƒé‡
â”œâ”€â”€ optimizer.pt          # ä¼˜åŒ–å™¨çŠ¶æ€
â”œâ”€â”€ scheduler.pt          # å­¦ä¹ ç‡è°ƒåº¦å™¨çŠ¶æ€ï¼ˆå¦‚æœæœ‰ï¼‰
â”œâ”€â”€ ema_model.pt          # EMA æ¨¡å‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
â””â”€â”€ training_state.json   # è®­ç»ƒçŠ¶æ€ï¼ˆepochã€stepï¼‰
```

## ğŸ” æ£€æŸ¥ç‚¹å†…å®¹

### training_state.json

```json
{
  "global_step": 6100,
  "current_epoch": 117
}
```

- `global_step`: å…¨å±€è®­ç»ƒæ­¥æ•°
- `current_epoch`: å½“å‰ epochï¼ˆä» 0 å¼€å§‹ï¼‰

## ğŸ’¡ ä½¿ç”¨åœºæ™¯

### åœºæ™¯1: è®­ç»ƒä¸­æ–­åæ¢å¤

```bash
# è®­ç»ƒä¸­æ–­åï¼Œä»æœ€åä¸€ä¸ªæ£€æŸ¥ç‚¹æ¢å¤
./run_train.sh \
    --config configs/train_config.yaml \
    --resume ./outputs/checkpoint-epoch-118
```

### åœºæ™¯2: ç»§ç»­æœªå®Œæˆçš„è®­ç»ƒ

```bash
# ç»§ç»­è®­ç»ƒåˆ° 200 epochsï¼ˆå½“å‰å·²å®Œæˆ 118ï¼‰
./run_train.sh \
    --config configs/train_config.yaml \
    --resume ./outputs/checkpoint-epoch-118
```

### åœºæ™¯3: ä»ç‰¹å®šæ£€æŸ¥ç‚¹æ¢å¤

```bash
# ä»ä»»æ„æ£€æŸ¥ç‚¹æ¢å¤
./run_train.sh \
    --config configs/train_config.yaml \
    --resume ./outputs/checkpoint-5000
```

## âš™ï¸ å·¥ä½œåŸç†

### æ¢å¤æµç¨‹

1. **åŠ è½½æ¨¡å‹æƒé‡**
   - è‡ªåŠ¨å¤„ç† `torch.compile` ç¼–è¯‘åçš„é”®å
   - æ”¯æŒä»ä¸åŒè®¾å¤‡åŠ è½½

2. **æ¢å¤ä¼˜åŒ–å™¨çŠ¶æ€**
   - æ¢å¤ä¼˜åŒ–å™¨çš„å†…éƒ¨çŠ¶æ€
   - ä¿æŒå­¦ä¹ ç‡ç­‰å‚æ•°

3. **æ¢å¤è®­ç»ƒè¿›åº¦**
   - ä»ä¿å­˜çš„ epoch ç»§ç»­
   - ä»ä¿å­˜çš„ step ç»§ç»­

4. **æ¢å¤å­¦ä¹ ç‡è°ƒåº¦å™¨**
   - ä¿æŒå­¦ä¹ ç‡è°ƒåº¦çŠ¶æ€
   - ç»§ç»­æ­£ç¡®çš„å­¦ä¹ ç‡è¡°å‡

### è®­ç»ƒå¾ªç¯

```python
# ä»æ¢å¤çš„ epoch ç»§ç»­
for epoch in range(start_epoch, num_epochs):
    # è®­ç»ƒé€»è¾‘
    ...
```

## ğŸ“Š ç¤ºä¾‹

### ç¤ºä¾‹1: æŸ¥çœ‹å¯ç”¨çš„æ£€æŸ¥ç‚¹

```bash
# åˆ—å‡ºæ‰€æœ‰æ£€æŸ¥ç‚¹
ls -1 outputs/checkpoint-*

# æŸ¥çœ‹æœ€æ–°æ£€æŸ¥ç‚¹
ls -1t outputs/checkpoint-* | head -1
```

### ç¤ºä¾‹2: æ¢å¤è®­ç»ƒ

```bash
# ä»æœ€æ–°æ£€æŸ¥ç‚¹æ¢å¤
LATEST_CHECKPOINT=$(ls -1t outputs/checkpoint-* | head -1)
./run_train.sh \
    --config configs/train_config.yaml \
    --resume "$LATEST_CHECKPOINT"
```

### ç¤ºä¾‹3: æ£€æŸ¥è®­ç»ƒçŠ¶æ€

```bash
# æŸ¥çœ‹è®­ç»ƒçŠ¶æ€
cat outputs/checkpoint-epoch-118/training_state.json
```

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. æ£€æŸ¥ç‚¹å…¼å®¹æ€§

- âœ… æ”¯æŒä»ç›¸åŒé…ç½®çš„æ£€æŸ¥ç‚¹æ¢å¤
- âš ï¸ å¦‚æœæ¨¡å‹é…ç½®æ”¹å˜ï¼Œå¯èƒ½æ— æ³•æ¢å¤
- âš ï¸ å¦‚æœæ•°æ®é›†æ”¹å˜ï¼Œéœ€è¦é‡æ–°åˆ›å»ºæ•°æ®åŠ è½½å™¨

### 2. è®¾å¤‡å…¼å®¹æ€§

- âœ… è‡ªåŠ¨å¤„ç†è®¾å¤‡æ˜ å°„ï¼ˆCPU â†” GPUï¼‰
- âœ… æ”¯æŒåœ¨ä¸åŒ GPU ä¸Šæ¢å¤

### 3. è®­ç»ƒçŠ¶æ€

- âœ… è‡ªåŠ¨ä»ä¿å­˜çš„ epoch ç»§ç»­
- âœ… è‡ªåŠ¨ä»ä¿å­˜çš„ step ç»§ç»­
- âœ… ä¿æŒä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨çŠ¶æ€

### 4. torch.compile å…¼å®¹æ€§

- âœ… è‡ªåŠ¨å¤„ç†ç¼–è¯‘åçš„é”®åï¼ˆ`_orig_mod.` å‰ç¼€ï¼‰
- âœ… æ”¯æŒä»ç¼–è¯‘åçš„æ£€æŸ¥ç‚¹æ¢å¤

## ğŸ”§ æ•…éšœæ’é™¤

### é—®é¢˜1: æ£€æŸ¥ç‚¹ä¸å­˜åœ¨

**é”™è¯¯**ï¼š
```
æ£€æŸ¥ç‚¹è·¯å¾„ä¸å­˜åœ¨: ./outputs/checkpoint-epoch-118
```

**è§£å†³**ï¼š
```bash
# æ£€æŸ¥æ£€æŸ¥ç‚¹æ˜¯å¦å­˜åœ¨
ls -la outputs/checkpoint-epoch-118/

# ä½¿ç”¨æ­£ç¡®çš„è·¯å¾„
./run_train.sh --resume ./outputs/checkpoint-epoch-118
```

### é—®é¢˜2: æ¨¡å‹é”®åä¸åŒ¹é…

**é”™è¯¯**ï¼š
```
Missing key(s) in state_dict: ...
```

**è§£å†³**ï¼š
- ä»£ç å·²è‡ªåŠ¨å¤„ç† `torch.compile` ç¼–è¯‘åçš„é”®å
- å¦‚æœä»æœ‰é—®é¢˜ï¼Œæ£€æŸ¥æ¨¡å‹é…ç½®æ˜¯å¦ä¸€è‡´

### é—®é¢˜3: è®­ç»ƒçŠ¶æ€æ–‡ä»¶ä¸å­˜åœ¨

**è­¦å‘Š**ï¼š
```
è®­ç»ƒçŠ¶æ€æ–‡ä»¶ä¸å­˜åœ¨: training_state.json
```

**è§£å†³**ï¼š
- ä»£ç ä¼šå°è¯•ä»æ£€æŸ¥ç‚¹åç§°æ¨æ–­ epoch
- å¦‚æœæ— æ³•æ¨æ–­ï¼Œå°†ä» epoch 0 å¼€å§‹ï¼ˆä½†ä¼šä¿ç•™æ¨¡å‹å’Œä¼˜åŒ–å™¨çŠ¶æ€ï¼‰

## ğŸ“ æœ€ä½³å®è·µ

### 1. å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹

é…ç½®æ–‡ä»¶ä¸­å·²è®¾ç½®è‡ªåŠ¨ä¿å­˜ï¼š
```yaml
training:
  save_steps: 500  # æ¯ 500 æ­¥ä¿å­˜ä¸€æ¬¡
```

### 2. ä¿ç•™é‡è¦æ£€æŸ¥ç‚¹

```bash
# åªä¿ç•™æœ€æ–°çš„ 5 ä¸ªæ£€æŸ¥ç‚¹
cd outputs
ls -1td checkpoint-* | tail -n +6 | xargs rm -rf
```

### 3. å¤‡ä»½é‡è¦æ£€æŸ¥ç‚¹

```bash
# å¤‡ä»½æœ€ç»ˆæ£€æŸ¥ç‚¹
cp -r outputs/checkpoint-epoch-200 outputs/backup/
```

### 4. è®°å½•è®­ç»ƒè¿›åº¦

è®­ç»ƒæ—¥å¿—ä¼šè‡ªåŠ¨è®°å½•ï¼š
```bash
# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
tail -f outputs/train.log
```

## ğŸ¯ æ€»ç»“

æ–­ç‚¹ç»­ä¼ åŠŸèƒ½å·²å®Œå…¨æ”¯æŒï¼Œå¯ä»¥ï¼š

1. âœ… ä»ä»»æ„æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ
2. âœ… ä¿æŒå®Œæ•´çš„è®­ç»ƒçŠ¶æ€
3. âœ… è‡ªåŠ¨å¤„ç†å„ç§å…¼å®¹æ€§é—®é¢˜
4. âœ… æ— ç¼ç»§ç»­è®­ç»ƒ

**ä½¿ç”¨å»ºè®®**ï¼š
- è®­ç»ƒä¸­æ–­åï¼Œç«‹å³ä»æœ€æ–°æ£€æŸ¥ç‚¹æ¢å¤
- å®šæœŸæ£€æŸ¥æ£€æŸ¥ç‚¹æ˜¯å¦æ­£å¸¸ä¿å­˜
- ä¿ç•™é‡è¦çš„æ£€æŸ¥ç‚¹ä½œä¸ºå¤‡ä»½

---

**å¼€å§‹ä½¿ç”¨æ–­ç‚¹ç»­ä¼ åŠŸèƒ½ï¼Œè®©è®­ç»ƒæ›´åŠ å¯é ï¼** ğŸš€

